{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Encoder Training: \n",
    "Here I built an autoencoder that both reduces the dimensionality of the input data and compresses the range of embeddings between -1 and 1. Compressing the dimensionality and standardizing the inputs to be between a consistent range will make clustering with k-means easier and give equal weighting to each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_io as tfio\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from performance_evaluation import plot_training_history, evaluate_model_performance\n",
    "\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(\n",
    "    physical_devices[0], enable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_customer_engagement = pd.read_pickle(\n",
    "    'data/AE_Clustering/all_customer_engagement.pkl'\n",
    ").drop('custno', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = all_customer_engagement.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cust_engagement = keras.Input(shape=(Xs.shape[1],), name='All_Customer_Engagement')\n",
    "encoded = layers.Dense(120, activation='relu')(all_cust_engagement)\n",
    "encoded = layers.Dense(60, activation='relu')(encoded)\n",
    "encoded = layers.Dense(30, activation='tanh')(encoded)\n",
    "\n",
    "decoded = layers.Dense(60, activation='relu')(encoded)\n",
    "decoded = layers.Dense(120, activation='relu')(decoded)\n",
    "decoded = layers.Dense(283, activation='linear')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.Model(all_cust_engagement, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(\n",
    "    inputs=all_cust_engagement, \n",
    "    outputs=decoded, name=\"Basic_Auto_Encoder\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Basic_Auto_Encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "All_Customer_Engagement (Inp [(None, 283)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               34080     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                7260      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                1860      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 120)               7320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 283)               34243     \n",
      "=================================================================\n",
      "Total params: 86,593\n",
      "Trainable params: 86,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_opt = keras.optimizers.Adam(\n",
    "    learning_rate=0.00005,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name=\"Adam\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=adam_opt,\n",
    "    metrics=[keras.metrics.MeanSquaredError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/AE/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Existing Logs in TensorBoard\n",
    "!rm -r /home/ben/gitrepos/shfly/logs/AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 4.8000 - mean_squared_error: 4.8000WARNING:tensorflow:From /home/ben/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0061s vs `on_train_batch_end` time: 0.0095s). Check your callbacks.\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 5.8585 - mean_squared_error: 5.8585 - val_loss: 3.4259 - val_mean_squared_error: 3.4259\n",
      "Epoch 2/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.8340 - mean_squared_error: 5.8340 - val_loss: 3.4114 - val_mean_squared_error: 3.4114\n",
      "Epoch 3/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.8103 - mean_squared_error: 5.8103 - val_loss: 3.3967 - val_mean_squared_error: 3.3967\n",
      "Epoch 4/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.7862 - mean_squared_error: 5.7862 - val_loss: 3.3818 - val_mean_squared_error: 3.3818\n",
      "Epoch 5/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.7621 - mean_squared_error: 5.7621 - val_loss: 3.3667 - val_mean_squared_error: 3.3667\n",
      "Epoch 6/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.7374 - mean_squared_error: 5.7374 - val_loss: 3.3503 - val_mean_squared_error: 3.3503\n",
      "Epoch 7/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.7098 - mean_squared_error: 5.7098 - val_loss: 3.3309 - val_mean_squared_error: 3.3309\n",
      "Epoch 8/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.6781 - mean_squared_error: 5.6781 - val_loss: 3.3099 - val_mean_squared_error: 3.3099\n",
      "Epoch 9/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.6461 - mean_squared_error: 5.6461 - val_loss: 3.2896 - val_mean_squared_error: 3.2896\n",
      "Epoch 10/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.6136 - mean_squared_error: 5.6136 - val_loss: 3.2681 - val_mean_squared_error: 3.2681\n",
      "Epoch 11/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.5780 - mean_squared_error: 5.5780 - val_loss: 3.2447 - val_mean_squared_error: 3.2447\n",
      "Epoch 12/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.5383 - mean_squared_error: 5.5383 - val_loss: 3.2182 - val_mean_squared_error: 3.2182\n",
      "Epoch 13/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.4956 - mean_squared_error: 5.4956 - val_loss: 3.1909 - val_mean_squared_error: 3.1909\n",
      "Epoch 14/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.4521 - mean_squared_error: 5.4521 - val_loss: 3.1636 - val_mean_squared_error: 3.1636\n",
      "Epoch 15/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.4081 - mean_squared_error: 5.4081 - val_loss: 3.1361 - val_mean_squared_error: 3.1361\n",
      "Epoch 16/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.3636 - mean_squared_error: 5.3636 - val_loss: 3.1084 - val_mean_squared_error: 3.1084\n",
      "Epoch 17/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.3186 - mean_squared_error: 5.3186 - val_loss: 3.0806 - val_mean_squared_error: 3.0806\n",
      "Epoch 18/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.2734 - mean_squared_error: 5.2734 - val_loss: 3.0525 - val_mean_squared_error: 3.0525\n",
      "Epoch 19/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.2275 - mean_squared_error: 5.2275 - val_loss: 3.0240 - val_mean_squared_error: 3.0240\n",
      "Epoch 20/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.1810 - mean_squared_error: 5.1810 - val_loss: 2.9951 - val_mean_squared_error: 2.9951\n",
      "Epoch 21/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 5.1344 - mean_squared_error: 5.1344 - val_loss: 2.9659 - val_mean_squared_error: 2.9659\n",
      "Epoch 22/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 5.0872 - mean_squared_error: 5.0872 - val_loss: 2.9362 - val_mean_squared_error: 2.9362\n",
      "Epoch 23/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 5.0396 - mean_squared_error: 5.0396 - val_loss: 2.9063 - val_mean_squared_error: 2.9063\n",
      "Epoch 24/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.9921 - mean_squared_error: 4.9921 - val_loss: 2.8764 - val_mean_squared_error: 2.8764\n",
      "Epoch 25/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.9448 - mean_squared_error: 4.9448 - val_loss: 2.8467 - val_mean_squared_error: 2.8467\n",
      "Epoch 26/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 4.8981 - mean_squared_error: 4.8981 - val_loss: 2.8167 - val_mean_squared_error: 2.8167\n",
      "Epoch 27/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 4.8511 - mean_squared_error: 4.8511 - val_loss: 2.7869 - val_mean_squared_error: 2.7869\n",
      "Epoch 28/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 4.8049 - mean_squared_error: 4.8049 - val_loss: 2.7570 - val_mean_squared_error: 2.7570\n",
      "Epoch 29/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.7587 - mean_squared_error: 4.7587 - val_loss: 2.7270 - val_mean_squared_error: 2.7270\n",
      "Epoch 30/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 4.7126 - mean_squared_error: 4.7126 - val_loss: 2.6970 - val_mean_squared_error: 2.6970\n",
      "Epoch 31/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 4.6666 - mean_squared_error: 4.6666 - val_loss: 2.6665 - val_mean_squared_error: 2.6665\n",
      "Epoch 32/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.6203 - mean_squared_error: 4.6203 - val_loss: 2.6361 - val_mean_squared_error: 2.6361\n",
      "Epoch 33/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.5743 - mean_squared_error: 4.5743 - val_loss: 2.6059 - val_mean_squared_error: 2.6059\n",
      "Epoch 34/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.5283 - mean_squared_error: 4.5283 - val_loss: 2.5758 - val_mean_squared_error: 2.5758\n",
      "Epoch 35/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.4824 - mean_squared_error: 4.4824 - val_loss: 2.5450 - val_mean_squared_error: 2.5450\n",
      "Epoch 36/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.4358 - mean_squared_error: 4.4358 - val_loss: 2.5142 - val_mean_squared_error: 2.5142\n",
      "Epoch 37/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.3889 - mean_squared_error: 4.3889 - val_loss: 2.4833 - val_mean_squared_error: 2.4833\n",
      "Epoch 38/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.3419 - mean_squared_error: 4.3419 - val_loss: 2.4525 - val_mean_squared_error: 2.4525\n",
      "Epoch 39/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.2946 - mean_squared_error: 4.2946 - val_loss: 2.4215 - val_mean_squared_error: 2.4215\n",
      "Epoch 40/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.2477 - mean_squared_error: 4.2477 - val_loss: 2.3903 - val_mean_squared_error: 2.3903\n",
      "Epoch 41/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.2004 - mean_squared_error: 4.2004 - val_loss: 2.3592 - val_mean_squared_error: 2.3592\n",
      "Epoch 42/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.1534 - mean_squared_error: 4.1534 - val_loss: 2.3285 - val_mean_squared_error: 2.3285\n",
      "Epoch 43/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.1068 - mean_squared_error: 4.1068 - val_loss: 2.2982 - val_mean_squared_error: 2.2982\n",
      "Epoch 44/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 4.0605 - mean_squared_error: 4.0605 - val_loss: 2.2678 - val_mean_squared_error: 2.2678\n",
      "Epoch 45/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 4.0141 - mean_squared_error: 4.0141 - val_loss: 2.2378 - val_mean_squared_error: 2.2378\n",
      "Epoch 46/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 3.9681 - mean_squared_error: 3.9681 - val_loss: 2.2081 - val_mean_squared_error: 2.2081\n",
      "Epoch 47/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.9224 - mean_squared_error: 3.9224 - val_loss: 2.1784 - val_mean_squared_error: 2.1784\n",
      "Epoch 48/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 3.8769 - mean_squared_error: 3.8769 - val_loss: 2.1491 - val_mean_squared_error: 2.1491\n",
      "Epoch 49/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.8317 - mean_squared_error: 3.8317 - val_loss: 2.1199 - val_mean_squared_error: 2.1199\n",
      "Epoch 50/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.7863 - mean_squared_error: 3.7863 - val_loss: 2.0912 - val_mean_squared_error: 2.0912\n",
      "Epoch 51/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.7423 - mean_squared_error: 3.7423 - val_loss: 2.0623 - val_mean_squared_error: 2.0623\n",
      "Epoch 52/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.6979 - mean_squared_error: 3.6979 - val_loss: 2.0346 - val_mean_squared_error: 2.0346\n",
      "Epoch 53/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.6542 - mean_squared_error: 3.6542 - val_loss: 2.0066 - val_mean_squared_error: 2.0066\n",
      "Epoch 54/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.6107 - mean_squared_error: 3.6107 - val_loss: 1.9789 - val_mean_squared_error: 1.9789\n",
      "Epoch 55/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.5680 - mean_squared_error: 3.5680 - val_loss: 1.9519 - val_mean_squared_error: 1.9519\n",
      "Epoch 56/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.5254 - mean_squared_error: 3.5254 - val_loss: 1.9254 - val_mean_squared_error: 1.9254\n",
      "Epoch 57/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.4835 - mean_squared_error: 3.4835 - val_loss: 1.8987 - val_mean_squared_error: 1.8987\n",
      "Epoch 58/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.4411 - mean_squared_error: 3.4411 - val_loss: 1.8720 - val_mean_squared_error: 1.8720\n",
      "Epoch 59/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.3992 - mean_squared_error: 3.3992 - val_loss: 1.8455 - val_mean_squared_error: 1.8455\n",
      "Epoch 60/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.3572 - mean_squared_error: 3.3572 - val_loss: 1.8197 - val_mean_squared_error: 1.8197\n",
      "Epoch 61/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.3159 - mean_squared_error: 3.3159 - val_loss: 1.7937 - val_mean_squared_error: 1.7937\n",
      "Epoch 62/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.2742 - mean_squared_error: 3.2742 - val_loss: 1.7675 - val_mean_squared_error: 1.7675\n",
      "Epoch 63/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.2323 - mean_squared_error: 3.2323 - val_loss: 1.7413 - val_mean_squared_error: 1.7413\n",
      "Epoch 64/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.1905 - mean_squared_error: 3.1905 - val_loss: 1.7155 - val_mean_squared_error: 1.7155\n",
      "Epoch 65/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.1491 - mean_squared_error: 3.1491 - val_loss: 1.6899 - val_mean_squared_error: 1.6899\n",
      "Epoch 66/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.1084 - mean_squared_error: 3.1084 - val_loss: 1.6651 - val_mean_squared_error: 1.6651\n",
      "Epoch 67/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.0683 - mean_squared_error: 3.0683 - val_loss: 1.6407 - val_mean_squared_error: 1.6407\n",
      "Epoch 68/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.0286 - mean_squared_error: 3.0286 - val_loss: 1.6166 - val_mean_squared_error: 1.6166\n",
      "Epoch 69/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.9892 - mean_squared_error: 2.9892 - val_loss: 1.5922 - val_mean_squared_error: 1.5922\n",
      "Epoch 70/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.9497 - mean_squared_error: 2.9497 - val_loss: 1.5686 - val_mean_squared_error: 1.5686\n",
      "Epoch 71/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.9113 - mean_squared_error: 2.9113 - val_loss: 1.5459 - val_mean_squared_error: 1.5459\n",
      "Epoch 72/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.8742 - mean_squared_error: 2.8742 - val_loss: 1.5235 - val_mean_squared_error: 1.5235\n",
      "Epoch 73/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.8374 - mean_squared_error: 2.8374 - val_loss: 1.5019 - val_mean_squared_error: 1.5019\n",
      "Epoch 74/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.8011 - mean_squared_error: 2.8011 - val_loss: 1.4809 - val_mean_squared_error: 1.4809\n",
      "Epoch 75/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.7656 - mean_squared_error: 2.7656 - val_loss: 1.4597 - val_mean_squared_error: 1.4597\n",
      "Epoch 76/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.7308 - mean_squared_error: 2.7308 - val_loss: 1.4389 - val_mean_squared_error: 1.4389\n",
      "Epoch 77/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.6961 - mean_squared_error: 2.6961 - val_loss: 1.4187 - val_mean_squared_error: 1.4187\n",
      "Epoch 78/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.6621 - mean_squared_error: 2.6621 - val_loss: 1.3984 - val_mean_squared_error: 1.3984\n",
      "Epoch 79/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.6282 - mean_squared_error: 2.6282 - val_loss: 1.3785 - val_mean_squared_error: 1.3785\n",
      "Epoch 80/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.5951 - mean_squared_error: 2.5951 - val_loss: 1.3593 - val_mean_squared_error: 1.3593\n",
      "Epoch 81/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.5621 - mean_squared_error: 2.5621 - val_loss: 1.3403 - val_mean_squared_error: 1.3403\n",
      "Epoch 82/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.5301 - mean_squared_error: 2.5301 - val_loss: 1.3216 - val_mean_squared_error: 1.3216\n",
      "Epoch 83/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.4978 - mean_squared_error: 2.4978 - val_loss: 1.3031 - val_mean_squared_error: 1.3031\n",
      "Epoch 84/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.4663 - mean_squared_error: 2.4663 - val_loss: 1.2847 - val_mean_squared_error: 1.2847\n",
      "Epoch 85/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.4349 - mean_squared_error: 2.4349 - val_loss: 1.2664 - val_mean_squared_error: 1.2664\n",
      "Epoch 86/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.4039 - mean_squared_error: 2.4039 - val_loss: 1.2486 - val_mean_squared_error: 1.2486\n",
      "Epoch 87/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.3742 - mean_squared_error: 2.3742 - val_loss: 1.2313 - val_mean_squared_error: 1.2313\n",
      "Epoch 88/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.3446 - mean_squared_error: 2.3446 - val_loss: 1.2141 - val_mean_squared_error: 1.2141\n",
      "Epoch 89/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.3148 - mean_squared_error: 2.3148 - val_loss: 1.1976 - val_mean_squared_error: 1.1976\n",
      "Epoch 90/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2865 - mean_squared_error: 2.2865 - val_loss: 1.1808 - val_mean_squared_error: 1.1808\n",
      "Epoch 91/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2574 - mean_squared_error: 2.2574 - val_loss: 1.1646 - val_mean_squared_error: 1.1646\n",
      "Epoch 92/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2292 - mean_squared_error: 2.2292 - val_loss: 1.1479 - val_mean_squared_error: 1.1479\n",
      "Epoch 93/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2008 - mean_squared_error: 2.2008 - val_loss: 1.1325 - val_mean_squared_error: 1.1325\n",
      "Epoch 94/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1735 - mean_squared_error: 2.1735 - val_loss: 1.1159 - val_mean_squared_error: 1.1159\n",
      "Epoch 95/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1458 - mean_squared_error: 2.1458 - val_loss: 1.1002 - val_mean_squared_error: 1.1002\n",
      "Epoch 96/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1194 - mean_squared_error: 2.1194 - val_loss: 1.0852 - val_mean_squared_error: 1.0852\n",
      "Epoch 97/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0930 - mean_squared_error: 2.0930 - val_loss: 1.0699 - val_mean_squared_error: 1.0699\n",
      "Epoch 98/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0667 - mean_squared_error: 2.0667 - val_loss: 1.0545 - val_mean_squared_error: 1.0545\n",
      "Epoch 99/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0414 - mean_squared_error: 2.0414 - val_loss: 1.0400 - val_mean_squared_error: 1.0400\n",
      "Epoch 100/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.0166 - mean_squared_error: 2.0166 - val_loss: 1.0266 - val_mean_squared_error: 1.0266\n",
      "Epoch 101/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.9922 - mean_squared_error: 1.9922 - val_loss: 1.0116 - val_mean_squared_error: 1.0116\n",
      "Epoch 102/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9680 - mean_squared_error: 1.9680 - val_loss: 0.9976 - val_mean_squared_error: 0.9976\n",
      "Epoch 103/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.9442 - mean_squared_error: 1.9442 - val_loss: 0.9834 - val_mean_squared_error: 0.9834\n",
      "Epoch 104/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.9203 - mean_squared_error: 1.9203 - val_loss: 0.9695 - val_mean_squared_error: 0.9695\n",
      "Epoch 105/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.8973 - mean_squared_error: 1.8973 - val_loss: 0.9563 - val_mean_squared_error: 0.9563\n",
      "Epoch 106/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.8742 - mean_squared_error: 1.8742 - val_loss: 0.9430 - val_mean_squared_error: 0.9430\n",
      "Epoch 107/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.8527 - mean_squared_error: 1.8527 - val_loss: 0.9299 - val_mean_squared_error: 0.9299\n",
      "Epoch 108/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.8304 - mean_squared_error: 1.8304 - val_loss: 0.9177 - val_mean_squared_error: 0.9177\n",
      "Epoch 109/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.8090 - mean_squared_error: 1.8090 - val_loss: 0.9042 - val_mean_squared_error: 0.9042\n",
      "Epoch 110/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.7878 - mean_squared_error: 1.7878 - val_loss: 0.8925 - val_mean_squared_error: 0.8925\n",
      "Epoch 111/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.7665 - mean_squared_error: 1.7665 - val_loss: 0.8802 - val_mean_squared_error: 0.8802\n",
      "Epoch 112/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.7457 - mean_squared_error: 1.7457 - val_loss: 0.8681 - val_mean_squared_error: 0.8681\n",
      "Epoch 113/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.7253 - mean_squared_error: 1.7253 - val_loss: 0.8563 - val_mean_squared_error: 0.8563\n",
      "Epoch 114/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.7055 - mean_squared_error: 1.7055 - val_loss: 0.8446 - val_mean_squared_error: 0.8446\n",
      "Epoch 115/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6858 - mean_squared_error: 1.6858 - val_loss: 0.8336 - val_mean_squared_error: 0.8336\n",
      "Epoch 116/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.6663 - mean_squared_error: 1.6663 - val_loss: 0.8222 - val_mean_squared_error: 0.8222\n",
      "Epoch 117/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6470 - mean_squared_error: 1.6470 - val_loss: 0.8111 - val_mean_squared_error: 0.8111\n",
      "Epoch 118/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6276 - mean_squared_error: 1.6276 - val_loss: 0.7998 - val_mean_squared_error: 0.7998\n",
      "Epoch 119/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6090 - mean_squared_error: 1.6090 - val_loss: 0.7891 - val_mean_squared_error: 0.7891\n",
      "Epoch 120/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5906 - mean_squared_error: 1.5906 - val_loss: 0.7791 - val_mean_squared_error: 0.7791\n",
      "Epoch 121/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5730 - mean_squared_error: 1.5730 - val_loss: 0.7689 - val_mean_squared_error: 0.7689\n",
      "Epoch 122/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5561 - mean_squared_error: 1.5561 - val_loss: 0.7590 - val_mean_squared_error: 0.7590\n",
      "Epoch 123/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5383 - mean_squared_error: 1.5383 - val_loss: 0.7489 - val_mean_squared_error: 0.7489\n",
      "Epoch 124/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.5219 - mean_squared_error: 1.5219 - val_loss: 0.7397 - val_mean_squared_error: 0.7397\n",
      "Epoch 125/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5051 - mean_squared_error: 1.5051 - val_loss: 0.7298 - val_mean_squared_error: 0.7298\n",
      "Epoch 126/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.4887 - mean_squared_error: 1.4887 - val_loss: 0.7207 - val_mean_squared_error: 0.7207\n",
      "Epoch 127/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.4728 - mean_squared_error: 1.4728 - val_loss: 0.7118 - val_mean_squared_error: 0.7118\n",
      "Epoch 128/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.4571 - mean_squared_error: 1.4571 - val_loss: 0.7024 - val_mean_squared_error: 0.7024\n",
      "Epoch 129/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.4408 - mean_squared_error: 1.4408 - val_loss: 0.6936 - val_mean_squared_error: 0.6936\n",
      "Epoch 130/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.4252 - mean_squared_error: 1.4252 - val_loss: 0.6850 - val_mean_squared_error: 0.6850\n",
      "Epoch 131/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.4102 - mean_squared_error: 1.4102 - val_loss: 0.6759 - val_mean_squared_error: 0.6759\n",
      "Epoch 132/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.3951 - mean_squared_error: 1.3951 - val_loss: 0.6676 - val_mean_squared_error: 0.6676\n",
      "Epoch 133/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.3804 - mean_squared_error: 1.3804 - val_loss: 0.6603 - val_mean_squared_error: 0.6603\n",
      "Epoch 134/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.3659 - mean_squared_error: 1.3659 - val_loss: 0.6512 - val_mean_squared_error: 0.6512\n",
      "Epoch 135/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.3511 - mean_squared_error: 1.3511 - val_loss: 0.6434 - val_mean_squared_error: 0.6434\n",
      "Epoch 136/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.3370 - mean_squared_error: 1.3370 - val_loss: 0.6346 - val_mean_squared_error: 0.6346\n",
      "Epoch 137/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.3225 - mean_squared_error: 1.3225 - val_loss: 0.6268 - val_mean_squared_error: 0.6268\n",
      "Epoch 138/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.3087 - mean_squared_error: 1.3087 - val_loss: 0.6194 - val_mean_squared_error: 0.6194\n",
      "Epoch 139/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.2953 - mean_squared_error: 1.2953 - val_loss: 0.6119 - val_mean_squared_error: 0.6119\n",
      "Epoch 140/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.2817 - mean_squared_error: 1.2817 - val_loss: 0.6040 - val_mean_squared_error: 0.6040\n",
      "Epoch 141/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.2687 - mean_squared_error: 1.2687 - val_loss: 0.5975 - val_mean_squared_error: 0.5975\n",
      "Epoch 142/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.2558 - mean_squared_error: 1.2558 - val_loss: 0.5899 - val_mean_squared_error: 0.5899\n",
      "Epoch 143/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.2430 - mean_squared_error: 1.2430 - val_loss: 0.5831 - val_mean_squared_error: 0.5831\n",
      "Epoch 144/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.2303 - mean_squared_error: 1.2303 - val_loss: 0.5760 - val_mean_squared_error: 0.5760\n",
      "Epoch 145/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.2186 - mean_squared_error: 1.2186 - val_loss: 0.5696 - val_mean_squared_error: 0.5696\n",
      "Epoch 146/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.2067 - mean_squared_error: 1.2067 - val_loss: 0.5637 - val_mean_squared_error: 0.5637\n",
      "Epoch 147/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.1940 - mean_squared_error: 1.1940 - val_loss: 0.5558 - val_mean_squared_error: 0.5558\n",
      "Epoch 148/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.1812 - mean_squared_error: 1.1812 - val_loss: 0.5491 - val_mean_squared_error: 0.5491\n",
      "Epoch 149/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.1697 - mean_squared_error: 1.1697 - val_loss: 0.5426 - val_mean_squared_error: 0.5426\n",
      "Epoch 150/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.1575 - mean_squared_error: 1.1575 - val_loss: 0.5377 - val_mean_squared_error: 0.5377\n",
      "Epoch 151/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.1457 - mean_squared_error: 1.1457 - val_loss: 0.5302 - val_mean_squared_error: 0.5302\n",
      "Epoch 152/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.1338 - mean_squared_error: 1.1338 - val_loss: 0.5237 - val_mean_squared_error: 0.5237\n",
      "Epoch 153/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.1225 - mean_squared_error: 1.1225 - val_loss: 0.5178 - val_mean_squared_error: 0.5178\n",
      "Epoch 154/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.1106 - mean_squared_error: 1.1106 - val_loss: 0.5119 - val_mean_squared_error: 0.5119\n",
      "Epoch 155/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.0995 - mean_squared_error: 1.0995 - val_loss: 0.5062 - val_mean_squared_error: 0.5062\n",
      "Epoch 156/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0892 - mean_squared_error: 1.0892 - val_loss: 0.5002 - val_mean_squared_error: 0.5002\n",
      "Epoch 157/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0784 - mean_squared_error: 1.0784 - val_loss: 0.4969 - val_mean_squared_error: 0.4969\n",
      "Epoch 158/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.0684 - mean_squared_error: 1.0684 - val_loss: 0.4892 - val_mean_squared_error: 0.4892\n",
      "Epoch 159/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0575 - mean_squared_error: 1.0575 - val_loss: 0.4837 - val_mean_squared_error: 0.4837\n",
      "Epoch 160/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.0470 - mean_squared_error: 1.0470 - val_loss: 0.4783 - val_mean_squared_error: 0.4783\n",
      "Epoch 161/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0368 - mean_squared_error: 1.0368 - val_loss: 0.4735 - val_mean_squared_error: 0.4735\n",
      "Epoch 162/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.0271 - mean_squared_error: 1.0271 - val_loss: 0.4681 - val_mean_squared_error: 0.4681\n",
      "Epoch 163/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.0172 - mean_squared_error: 1.0172 - val_loss: 0.4631 - val_mean_squared_error: 0.4631\n",
      "Epoch 164/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1.0079 - mean_squared_error: 1.0079 - val_loss: 0.4583 - val_mean_squared_error: 0.4583\n",
      "Epoch 165/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9988 - mean_squared_error: 0.9988 - val_loss: 0.4544 - val_mean_squared_error: 0.4544\n",
      "Epoch 166/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9893 - mean_squared_error: 0.9893 - val_loss: 0.4504 - val_mean_squared_error: 0.4504\n",
      "Epoch 167/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9807 - mean_squared_error: 0.9807 - val_loss: 0.4448 - val_mean_squared_error: 0.4448\n",
      "Epoch 168/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9712 - mean_squared_error: 0.9712 - val_loss: 0.4409 - val_mean_squared_error: 0.4409\n",
      "Epoch 169/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9620 - mean_squared_error: 0.9620 - val_loss: 0.4370 - val_mean_squared_error: 0.4370\n",
      "Epoch 170/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.9533 - mean_squared_error: 0.9533 - val_loss: 0.4316 - val_mean_squared_error: 0.4316\n",
      "Epoch 171/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.9443 - mean_squared_error: 0.9443 - val_loss: 0.4283 - val_mean_squared_error: 0.4283\n",
      "Epoch 172/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9365 - mean_squared_error: 0.9365 - val_loss: 0.4237 - val_mean_squared_error: 0.4237\n",
      "Epoch 173/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9284 - mean_squared_error: 0.9284 - val_loss: 0.4192 - val_mean_squared_error: 0.4192\n",
      "Epoch 174/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9195 - mean_squared_error: 0.9195 - val_loss: 0.4158 - val_mean_squared_error: 0.4158\n",
      "Epoch 175/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9120 - mean_squared_error: 0.9120 - val_loss: 0.4122 - val_mean_squared_error: 0.4122\n",
      "Epoch 176/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.9042 - mean_squared_error: 0.9042 - val_loss: 0.4081 - val_mean_squared_error: 0.4081\n",
      "Epoch 177/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.8955 - mean_squared_error: 0.8955 - val_loss: 0.4042 - val_mean_squared_error: 0.4042\n",
      "Epoch 178/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8882 - mean_squared_error: 0.8882 - val_loss: 0.4003 - val_mean_squared_error: 0.4003\n",
      "Epoch 179/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8813 - mean_squared_error: 0.8813 - val_loss: 0.3978 - val_mean_squared_error: 0.3978\n",
      "Epoch 180/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8744 - mean_squared_error: 0.8744 - val_loss: 0.3935 - val_mean_squared_error: 0.3935\n",
      "Epoch 181/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8665 - mean_squared_error: 0.8665 - val_loss: 0.3907 - val_mean_squared_error: 0.3907\n",
      "Epoch 182/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8597 - mean_squared_error: 0.8597 - val_loss: 0.3872 - val_mean_squared_error: 0.3872\n",
      "Epoch 183/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8523 - mean_squared_error: 0.8523 - val_loss: 0.3848 - val_mean_squared_error: 0.3848\n",
      "Epoch 184/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8465 - mean_squared_error: 0.8465 - val_loss: 0.3815 - val_mean_squared_error: 0.3815\n",
      "Epoch 185/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.8392 - mean_squared_error: 0.8392 - val_loss: 0.3778 - val_mean_squared_error: 0.3778\n",
      "Epoch 186/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8326 - mean_squared_error: 0.8326 - val_loss: 0.3755 - val_mean_squared_error: 0.3755\n",
      "Epoch 187/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8268 - mean_squared_error: 0.8268 - val_loss: 0.3718 - val_mean_squared_error: 0.3718\n",
      "Epoch 188/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8197 - mean_squared_error: 0.8197 - val_loss: 0.3695 - val_mean_squared_error: 0.3695\n",
      "Epoch 189/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8138 - mean_squared_error: 0.8138 - val_loss: 0.3670 - val_mean_squared_error: 0.3670\n",
      "Epoch 190/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8079 - mean_squared_error: 0.8079 - val_loss: 0.3637 - val_mean_squared_error: 0.3637\n",
      "Epoch 191/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.8029 - mean_squared_error: 0.8029 - val_loss: 0.3632 - val_mean_squared_error: 0.3632\n",
      "Epoch 192/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7979 - mean_squared_error: 0.7979 - val_loss: 0.3585 - val_mean_squared_error: 0.3585\n",
      "Epoch 193/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7919 - mean_squared_error: 0.7919 - val_loss: 0.3615 - val_mean_squared_error: 0.3615\n",
      "Epoch 194/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7874 - mean_squared_error: 0.7874 - val_loss: 0.3538 - val_mean_squared_error: 0.3538\n",
      "Epoch 195/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7808 - mean_squared_error: 0.7808 - val_loss: 0.3514 - val_mean_squared_error: 0.3514\n",
      "Epoch 196/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7742 - mean_squared_error: 0.7742 - val_loss: 0.3511 - val_mean_squared_error: 0.3511\n",
      "Epoch 197/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7695 - mean_squared_error: 0.7695 - val_loss: 0.3466 - val_mean_squared_error: 0.3466\n",
      "Epoch 198/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7634 - mean_squared_error: 0.7634 - val_loss: 0.3440 - val_mean_squared_error: 0.3440\n",
      "Epoch 199/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7589 - mean_squared_error: 0.7589 - val_loss: 0.3438 - val_mean_squared_error: 0.3438\n",
      "Epoch 200/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7531 - mean_squared_error: 0.7531 - val_loss: 0.3406 - val_mean_squared_error: 0.3406\n",
      "Epoch 201/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7491 - mean_squared_error: 0.7491 - val_loss: 0.3385 - val_mean_squared_error: 0.3385\n",
      "Epoch 202/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7424 - mean_squared_error: 0.7424 - val_loss: 0.3361 - val_mean_squared_error: 0.3361\n",
      "Epoch 203/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7374 - mean_squared_error: 0.7374 - val_loss: 0.3338 - val_mean_squared_error: 0.3338\n",
      "Epoch 204/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7326 - mean_squared_error: 0.7326 - val_loss: 0.3315 - val_mean_squared_error: 0.3315\n",
      "Epoch 205/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7274 - mean_squared_error: 0.7274 - val_loss: 0.3295 - val_mean_squared_error: 0.3295\n",
      "Epoch 206/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7235 - mean_squared_error: 0.7235 - val_loss: 0.3280 - val_mean_squared_error: 0.3280\n",
      "Epoch 207/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7189 - mean_squared_error: 0.7189 - val_loss: 0.3257 - val_mean_squared_error: 0.3257\n",
      "Epoch 208/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7139 - mean_squared_error: 0.7139 - val_loss: 0.3240 - val_mean_squared_error: 0.3240\n",
      "Epoch 209/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7095 - mean_squared_error: 0.7095 - val_loss: 0.3220 - val_mean_squared_error: 0.3220\n",
      "Epoch 210/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7051 - mean_squared_error: 0.7051 - val_loss: 0.3209 - val_mean_squared_error: 0.3209\n",
      "Epoch 211/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7008 - mean_squared_error: 0.7008 - val_loss: 0.3187 - val_mean_squared_error: 0.3187\n",
      "Epoch 212/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6963 - mean_squared_error: 0.6963 - val_loss: 0.3170 - val_mean_squared_error: 0.3170\n",
      "Epoch 213/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6921 - mean_squared_error: 0.6921 - val_loss: 0.3153 - val_mean_squared_error: 0.3153\n",
      "Epoch 214/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6878 - mean_squared_error: 0.6878 - val_loss: 0.3141 - val_mean_squared_error: 0.3141\n",
      "Epoch 215/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.6843 - mean_squared_error: 0.6843 - val_loss: 0.3123 - val_mean_squared_error: 0.3123\n",
      "Epoch 216/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6798 - mean_squared_error: 0.6798 - val_loss: 0.3109 - val_mean_squared_error: 0.3109\n",
      "Epoch 217/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.6760 - mean_squared_error: 0.6760 - val_loss: 0.3094 - val_mean_squared_error: 0.3094\n",
      "Epoch 218/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6720 - mean_squared_error: 0.6720 - val_loss: 0.3076 - val_mean_squared_error: 0.3076\n",
      "Epoch 219/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.6685 - mean_squared_error: 0.6685 - val_loss: 0.3066 - val_mean_squared_error: 0.3066\n",
      "Epoch 220/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.6648 - mean_squared_error: 0.6648 - val_loss: 0.3052 - val_mean_squared_error: 0.3052\n",
      "Epoch 221/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6610 - mean_squared_error: 0.6610 - val_loss: 0.3036 - val_mean_squared_error: 0.3036\n",
      "Epoch 222/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.6569 - mean_squared_error: 0.6569 - val_loss: 0.3038 - val_mean_squared_error: 0.3038\n",
      "Epoch 223/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.6541 - mean_squared_error: 0.6541 - val_loss: 0.3021 - val_mean_squared_error: 0.3021\n",
      "Epoch 224/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6501 - mean_squared_error: 0.6501 - val_loss: 0.2997 - val_mean_squared_error: 0.2997\n",
      "Epoch 225/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6464 - mean_squared_error: 0.6464 - val_loss: 0.2982 - val_mean_squared_error: 0.2982\n",
      "Epoch 226/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6433 - mean_squared_error: 0.6433 - val_loss: 0.2964 - val_mean_squared_error: 0.2964\n",
      "Epoch 227/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6399 - mean_squared_error: 0.6399 - val_loss: 0.2962 - val_mean_squared_error: 0.2962\n",
      "Epoch 228/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.6359 - mean_squared_error: 0.6359 - val_loss: 0.2940 - val_mean_squared_error: 0.2940\n",
      "Epoch 229/250\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.6330 - mean_squared_error: 0.6330 - val_loss: 0.2937 - val_mean_squared_error: 0.2937\n",
      "Epoch 230/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6299 - mean_squared_error: 0.6299 - val_loss: 0.2923 - val_mean_squared_error: 0.2923\n",
      "Epoch 231/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6264 - mean_squared_error: 0.6264 - val_loss: 0.2907 - val_mean_squared_error: 0.2907\n",
      "Epoch 232/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6232 - mean_squared_error: 0.6232 - val_loss: 0.2902 - val_mean_squared_error: 0.2902\n",
      "Epoch 233/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6206 - mean_squared_error: 0.6206 - val_loss: 0.2888 - val_mean_squared_error: 0.2888\n",
      "Epoch 234/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6170 - mean_squared_error: 0.6170 - val_loss: 0.2874 - val_mean_squared_error: 0.2874\n",
      "Epoch 235/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6141 - mean_squared_error: 0.6141 - val_loss: 0.2864 - val_mean_squared_error: 0.2864\n",
      "Epoch 236/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6116 - mean_squared_error: 0.6116 - val_loss: 0.2857 - val_mean_squared_error: 0.2857\n",
      "Epoch 237/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6091 - mean_squared_error: 0.6091 - val_loss: 0.2859 - val_mean_squared_error: 0.2859\n",
      "Epoch 238/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6061 - mean_squared_error: 0.6061 - val_loss: 0.2841 - val_mean_squared_error: 0.2841\n",
      "Epoch 239/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6038 - mean_squared_error: 0.6038 - val_loss: 0.2829 - val_mean_squared_error: 0.2829\n",
      "Epoch 240/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6008 - mean_squared_error: 0.6008 - val_loss: 0.2813 - val_mean_squared_error: 0.2813\n",
      "Epoch 241/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5977 - mean_squared_error: 0.5977 - val_loss: 0.2802 - val_mean_squared_error: 0.2802\n",
      "Epoch 242/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5951 - mean_squared_error: 0.5951 - val_loss: 0.2794 - val_mean_squared_error: 0.2794\n",
      "Epoch 243/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5925 - mean_squared_error: 0.5925 - val_loss: 0.2782 - val_mean_squared_error: 0.2782\n",
      "Epoch 244/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5902 - mean_squared_error: 0.5902 - val_loss: 0.2772 - val_mean_squared_error: 0.2772\n",
      "Epoch 245/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5871 - mean_squared_error: 0.5871 - val_loss: 0.2770 - val_mean_squared_error: 0.2770\n",
      "Epoch 246/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5847 - mean_squared_error: 0.5847 - val_loss: 0.2764 - val_mean_squared_error: 0.2764\n",
      "Epoch 247/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5827 - mean_squared_error: 0.5827 - val_loss: 0.2748 - val_mean_squared_error: 0.2748\n",
      "Epoch 248/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5798 - mean_squared_error: 0.5798 - val_loss: 0.2748 - val_mean_squared_error: 0.2748\n",
      "Epoch 249/250\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5774 - mean_squared_error: 0.5774 - val_loss: 0.2755 - val_mean_squared_error: 0.2755\n",
      "Epoch 250/250\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5765 - mean_squared_error: 0.5765 - val_loss: 0.2727 - val_mean_squared_error: 0.2727\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    Xs,\n",
    "    Xs, batch_size=5000, epochs=250, validation_split=0.2,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_customer_engagement.pkl  encoder\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/AE_Clustering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_Xs = encoder.predict(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "      <td>63901.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.138159</td>\n",
       "      <td>0.064628</td>\n",
       "      <td>-0.077943</td>\n",
       "      <td>0.255132</td>\n",
       "      <td>0.196226</td>\n",
       "      <td>0.024565</td>\n",
       "      <td>-0.226669</td>\n",
       "      <td>0.065302</td>\n",
       "      <td>-0.137121</td>\n",
       "      <td>-0.176708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100814</td>\n",
       "      <td>0.194526</td>\n",
       "      <td>0.163162</td>\n",
       "      <td>-0.196011</td>\n",
       "      <td>0.095884</td>\n",
       "      <td>-0.230394</td>\n",
       "      <td>0.350982</td>\n",
       "      <td>0.172994</td>\n",
       "      <td>0.117882</td>\n",
       "      <td>0.036691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.241857</td>\n",
       "      <td>0.215367</td>\n",
       "      <td>0.216416</td>\n",
       "      <td>0.209165</td>\n",
       "      <td>0.221375</td>\n",
       "      <td>0.317046</td>\n",
       "      <td>0.276555</td>\n",
       "      <td>0.325870</td>\n",
       "      <td>0.281570</td>\n",
       "      <td>0.223803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218634</td>\n",
       "      <td>0.278527</td>\n",
       "      <td>0.209549</td>\n",
       "      <td>0.185014</td>\n",
       "      <td>0.361866</td>\n",
       "      <td>0.325953</td>\n",
       "      <td>0.254175</td>\n",
       "      <td>0.267631</td>\n",
       "      <td>0.193609</td>\n",
       "      <td>0.293436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.999872</td>\n",
       "      <td>-0.956004</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999997</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.931186</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999723</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.905770</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.045160</td>\n",
       "      <td>-0.034166</td>\n",
       "      <td>-0.216730</td>\n",
       "      <td>0.216925</td>\n",
       "      <td>0.080629</td>\n",
       "      <td>-0.157222</td>\n",
       "      <td>-0.326626</td>\n",
       "      <td>-0.183497</td>\n",
       "      <td>-0.271253</td>\n",
       "      <td>-0.313963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045134</td>\n",
       "      <td>-0.002395</td>\n",
       "      <td>0.100419</td>\n",
       "      <td>-0.249922</td>\n",
       "      <td>-0.172591</td>\n",
       "      <td>-0.448944</td>\n",
       "      <td>0.221628</td>\n",
       "      <td>-0.044069</td>\n",
       "      <td>0.031957</td>\n",
       "      <td>-0.110863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.144643</td>\n",
       "      <td>0.074095</td>\n",
       "      <td>-0.126938</td>\n",
       "      <td>0.303446</td>\n",
       "      <td>0.223042</td>\n",
       "      <td>-0.057559</td>\n",
       "      <td>-0.213260</td>\n",
       "      <td>0.058531</td>\n",
       "      <td>-0.145694</td>\n",
       "      <td>-0.230593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130019</td>\n",
       "      <td>0.195090</td>\n",
       "      <td>0.193820</td>\n",
       "      <td>-0.161751</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>-0.267251</td>\n",
       "      <td>0.385133</td>\n",
       "      <td>0.161995</td>\n",
       "      <td>0.117018</td>\n",
       "      <td>0.026096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.247992</td>\n",
       "      <td>0.164870</td>\n",
       "      <td>-0.002978</td>\n",
       "      <td>0.365640</td>\n",
       "      <td>0.325390</td>\n",
       "      <td>0.141791</td>\n",
       "      <td>-0.127317</td>\n",
       "      <td>0.346627</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>-0.112469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272230</td>\n",
       "      <td>0.356115</td>\n",
       "      <td>0.285589</td>\n",
       "      <td>-0.088045</td>\n",
       "      <td>0.381608</td>\n",
       "      <td>-0.021683</td>\n",
       "      <td>0.497102</td>\n",
       "      <td>0.338882</td>\n",
       "      <td>0.202991</td>\n",
       "      <td>0.149351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940320</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933814</td>\n",
       "      <td>0.961642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  63901.000000  63901.000000  63901.000000  63901.000000  63901.000000   \n",
       "mean       0.138159      0.064628     -0.077943      0.255132      0.196226   \n",
       "std        0.241857      0.215367      0.216416      0.209165      0.221375   \n",
       "min       -0.999999     -0.999872     -0.956004     -1.000000     -0.999997   \n",
       "25%        0.045160     -0.034166     -0.216730      0.216925      0.080629   \n",
       "50%        0.144643      0.074095     -0.126938      0.303446      0.223042   \n",
       "75%        0.247992      0.164870     -0.002978      0.365640      0.325390   \n",
       "max        1.000000      1.000000      1.000000      0.940320      0.999999   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  63901.000000  63901.000000  63901.000000  63901.000000  63901.000000   \n",
       "mean       0.024565     -0.226669      0.065302     -0.137121     -0.176708   \n",
       "std        0.317046      0.276555      0.325870      0.281570      0.223803   \n",
       "min       -1.000000     -1.000000     -1.000000     -1.000000     -0.931186   \n",
       "25%       -0.157222     -0.326626     -0.183497     -0.271253     -0.313963   \n",
       "50%       -0.057559     -0.213260      0.058531     -0.145694     -0.230593   \n",
       "75%        0.141791     -0.127317      0.346627      0.018450     -0.112469   \n",
       "max        1.000000      1.000000      1.000000      0.999996      1.000000   \n",
       "\n",
       "       ...            20            21            22            23  \\\n",
       "count  ...  63901.000000  63901.000000  63901.000000  63901.000000   \n",
       "mean   ...      0.100814      0.194526      0.163162     -0.196011   \n",
       "std    ...      0.218634      0.278527      0.209549      0.185014   \n",
       "min    ...     -1.000000     -0.999723     -1.000000     -1.000000   \n",
       "25%    ...     -0.045134     -0.002395      0.100419     -0.249922   \n",
       "50%    ...      0.130019      0.195090      0.193820     -0.161751   \n",
       "75%    ...      0.272230      0.356115      0.285589     -0.088045   \n",
       "max    ...      0.712651      1.000000      0.933814      0.961642   \n",
       "\n",
       "                 24            25            26            27            28  \\\n",
       "count  63901.000000  63901.000000  63901.000000  63901.000000  63901.000000   \n",
       "mean       0.095884     -0.230394      0.350982      0.172994      0.117882   \n",
       "std        0.361866      0.325953      0.254175      0.267631      0.193609   \n",
       "min       -1.000000     -1.000000     -1.000000     -0.905770     -1.000000   \n",
       "25%       -0.172591     -0.448944      0.221628     -0.044069      0.031957   \n",
       "50%        0.087708     -0.267251      0.385133      0.161995      0.117018   \n",
       "75%        0.381608     -0.021683      0.497102      0.338882      0.202991   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 29  \n",
       "count  63901.000000  \n",
       "mean       0.036691  \n",
       "std        0.293436  \n",
       "min       -1.000000  \n",
       "25%       -0.110863  \n",
       "50%        0.026096  \n",
       "75%        0.149351  \n",
       "max        0.999999  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(encoded_Xs).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save('data/AE_Clustering/encoder.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
