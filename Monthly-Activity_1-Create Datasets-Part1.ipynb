{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('max_columns',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Order Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_categories(prefix, current_name):\n",
    "    return f'{prefix}:{current_name}'\n",
    "\n",
    "def test_rename_categories():\n",
    "    obs = rename_categories(0,'It_Worked!')\n",
    "    exp = '0:It_Worked!'\n",
    "    print(obs)\n",
    "    print(exp)\n",
    "    assert obs == exp\n",
    "\n",
    "test_rename_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = pd.read_csv('data/order.csv')\n",
    "order['orderdate'] = pd.to_datetime(order['orderdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "order.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Order Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_96_overlap(prd_cat1, prd_cat2):\n",
    "    if prd_cat2 == 96:\n",
    "        prd_cat1 = 7\n",
    "    return prd_cat1\n",
    "\n",
    "def test_clean_96_overlap():\n",
    "    in_data = [\n",
    "        [0,1],\n",
    "        [3,96],\n",
    "        [7,96]\n",
    "    ]\n",
    "    obs = [clean_96_overlap(x[0], x[1]) for x in in_data]\n",
    "    exp = [0,7,7]\n",
    "    assert obs == exp\n",
    "\n",
    "test_clean_96_overlap()\n",
    "\n",
    "def prod_cat2_nan_fill(prd_cat1, prd_cat2):\n",
    "    if np.isnan(prd_cat2):\n",
    "        return -1*prd_cat1\n",
    "    else:\n",
    "        return prd_cat2\n",
    "\n",
    "def test_prod_cat2_nan_fill():\n",
    "    in_data = [\n",
    "        [1,np.nan],\n",
    "        [2,np.nan],\n",
    "        [3,199],\n",
    "        [1,2]\n",
    "    ]\n",
    "    obs = [prod_cat2_nan_fill(x[0], x[1]) for x in in_data]\n",
    "    exp = [-1,-2, 199, 2]\n",
    "    assert obs == exp, f'obs:{obs}, exp:{exp}'\n",
    "\n",
    "test_prod_cat2_nan_fill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order['prodcat2'] = order[['prodcat1', 'prodcat2']].apply(\n",
    "    lambda row: prod_cat2_nan_fill(row['prodcat1'], row['prodcat2']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order['prodcat1'] = order[['prodcat1', 'prodcat2']].apply(\n",
    "    lambda row: clean_96_overlap(row['prodcat1'], row['prodcat2']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Dummies for prodcat2 and prodcat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order['prodcat1'] = order[['prodcat1']].apply(lambda row: rename_categories('P1',row[0]), axis=1)\n",
    "order['prodcat2'] = order[['prodcat2']].apply(lambda row: rename_categories('P2',row[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_dummies = pd.get_dummies(order['prodcat1'])\n",
    "p2_dummies = pd.get_dummies(order['prodcat2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcat_columns = list(p1_dummies.columns) + list(p2_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_expanded = pd.concat([order, p1_dummies, p2_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary for Aggregation\n",
    "order_agg_dict = {}\n",
    "for pcat_column in pcat_columns:\n",
    "    order_agg_dict[pcat_column] = 'sum'\n",
    "order_agg_dict['orderdate'] = 'min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_totals = order_expanded.groupby(['ordno', 'custno'], as_index=False).agg(order_agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_totals['ordermonth'] = order_totals['orderdate'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert order_totals.shape[0] == len(order_totals['ordno'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Modeling Datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_dataset = order_totals[\n",
    "    ['ordno', 'custno', 'orderdate', 'ordermonth','P1:1.0','P1:2.0','P1:3.0','P1:4.0','P1:5.0','P1:7.0']\n",
    "].sort_values('ordno').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm Unique at Order Level\n",
    "assert (modeling_dataset[['ordno','custno']].drop_duplicates().shape[0] \n",
    "        == modeling_dataset[['ordno']].drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_orders = modeling_dataset.merge(\n",
    "    order_totals, on='custno', how='left',\n",
    "    suffixes=('_current', '_previous')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prev_orders = merged_orders[merged_orders['orderdate_current']> merged_orders['orderdate_previous']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prev_orders['days_before'] = (\n",
    "    all_prev_orders['orderdate_current'] - all_prev_orders['orderdate_previous']\n",
    ").astype('timedelta64[s]')/3600/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prev_orders_clean = all_prev_orders[\n",
    "    [\n",
    "        'ordno_current', 'days_before',\n",
    "        'P2:-1.0', 'P2:-7.0', 'P2:10.0', 'P2:100.0', 'P2:101.0', 'P2:102.0', 'P2:103.0', 'P2:104.0', 'P2:105.0',\n",
    "        'P2:106.0', 'P2:107.0', 'P2:108.0', 'P2:109.0', 'P2:11.0', 'P2:110.0', 'P2:111.0', 'P2:112.0', 'P2:113.0',\n",
    "        'P2:114.0', 'P2:115.0', 'P2:116.0', 'P2:117.0', 'P2:118.0', 'P2:119.0', 'P2:12.0', 'P2:120.0', 'P2:121.0',\n",
    "        'P2:122.0', 'P2:123.0', 'P2:124.0', 'P2:125.0', 'P2:126.0', 'P2:127.0', 'P2:128.0', 'P2:129.0', 'P2:13.0',\n",
    "        'P2:130.0', 'P2:131.0', 'P2:132.0', 'P2:133.0', 'P2:134.0', 'P2:135.0', 'P2:136.0', 'P2:137.0', 'P2:138.0',\n",
    "        'P2:139.0', 'P2:14.0', 'P2:140.0', 'P2:141.0', 'P2:142.0', 'P2:143.0', 'P2:144.0', 'P2:145.0', 'P2:146.0',\n",
    "        'P2:147.0', 'P2:148.0', 'P2:149.0', 'P2:15.0', 'P2:150.0', 'P2:151.0', 'P2:152.0', 'P2:153.0', 'P2:154.0',\n",
    "        'P2:155.0', 'P2:156.0', 'P2:157.0', 'P2:158.0', 'P2:159.0', 'P2:16.0', 'P2:160.0', 'P2:161.0', 'P2:162.0',\n",
    "        'P2:164.0', 'P2:165.0', 'P2:166.0', 'P2:167.0', 'P2:168.0', 'P2:169.0', 'P2:17.0', 'P2:170.0', 'P2:171.0',\n",
    "        'P2:172.0', 'P2:173.0', 'P2:174.0', 'P2:175.0', 'P2:176.0', 'P2:177.0', 'P2:178.0', 'P2:179.0', 'P2:18.0',\n",
    "        'P2:180.0', 'P2:181.0', 'P2:182.0', 'P2:183.0', 'P2:184.0', 'P2:185.0', 'P2:186.0', 'P2:187.0', 'P2:188.0',\n",
    "        'P2:189.0', 'P2:19.0', 'P2:190.0', 'P2:191.0', 'P2:192.0', 'P2:193.0', 'P2:194.0', 'P2:195.0', 'P2:196.0',\n",
    "        'P2:197.0', 'P2:198.0', 'P2:199.0', 'P2:2.0', 'P2:20.0', 'P2:200.0', 'P2:201.0', 'P2:202.0', 'P2:203.0',\n",
    "        'P2:204.0', 'P2:205.0', 'P2:206.0', 'P2:207.0', 'P2:208.0', 'P2:209.0', 'P2:21.0', 'P2:210.0', 'P2:211.0',\n",
    "        'P2:212.0', 'P2:213.0', 'P2:214.0', 'P2:215.0', 'P2:216.0', 'P2:217.0', 'P2:218.0', 'P2:219.0', 'P2:220.0',\n",
    "        'P2:221.0', 'P2:222.0', 'P2:223.0', 'P2:224.0', 'P2:225.0', 'P2:226.0', 'P2:227.0', 'P2:228.0', 'P2:229.0',\n",
    "        'P2:23.0', 'P2:230.0', 'P2:231.0', 'P2:232.0', 'P2:233.0', 'P2:234.0', 'P2:235.0', 'P2:236.0', 'P2:237.0',\n",
    "        'P2:238.0', 'P2:239.0', 'P2:24.0', 'P2:240.0', 'P2:241.0', 'P2:243.0', 'P2:244.0', 'P2:245.0', 'P2:246.0',\n",
    "        'P2:247.0', 'P2:248.0', 'P2:249.0', 'P2:25.0', 'P2:250.0', 'P2:251.0', 'P2:252.0', 'P2:253.0', 'P2:255.0',\n",
    "        'P2:256.0', 'P2:257.0', 'P2:258.0', 'P2:259.0', 'P2:26.0', 'P2:260.0', 'P2:261.0', 'P2:262.0', 'P2:263.0',\n",
    "        'P2:27.0', 'P2:28.0', 'P2:3.0', 'P2:30.0', 'P2:32.0', 'P2:33.0', 'P2:34.0', 'P2:35.0', 'P2:38.0',\n",
    "        'P2:39.0', 'P2:4.0', 'P2:40.0', 'P2:41.0', 'P2:42.0', 'P2:43.0', 'P2:44.0', 'P2:45.0', 'P2:46.0',\n",
    "        'P2:47.0', 'P2:48.0', 'P2:49.0', 'P2:5.0', 'P2:50.0', 'P2:51.0', 'P2:52.0', 'P2:53.0', 'P2:54.0',\n",
    "        'P2:55.0', 'P2:56.0', 'P2:57.0', 'P2:58.0', 'P2:59.0', 'P2:6.0', 'P2:60.0', 'P2:61.0', 'P2:62.0',\n",
    "        'P2:63.0', 'P2:64.0', 'P2:65.0', 'P2:66.0', 'P2:67.0', 'P2:69.0', 'P2:7.0', 'P2:70.0', 'P2:71.0',\n",
    "        'P2:72.0', 'P2:73.0', 'P2:74.0', 'P2:75.0', 'P2:76.0', 'P2:77.0', 'P2:78.0', 'P2:79.0', 'P2:8.0',\n",
    "        'P2:80.0', 'P2:81.0', 'P2:82.0', 'P2:83.0', 'P2:85.0', 'P2:86.0', 'P2:88.0', 'P2:89.0', 'P2:9.0',\n",
    "        'P2:90.0', 'P2:91.0', 'P2:92.0', 'P2:93.0', 'P2:94.0', 'P2:95.0', 'P2:96.0', 'P2:97.0', 'P2:98.0',\n",
    "        'P2:99.0' \n",
    "]\n",
    "\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_months_before(days):\n",
    "    i = 0\n",
    "    for max_days in range(30,30*24,30):\n",
    "        i+=1\n",
    "        if days<max_days:\n",
    "            return i\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prev_orders_clean['months_before'] = all_prev_orders_clean['days_before'].apply(get_months_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(all_prev_orders_clean['ordno_current']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate to Order and months_before level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prev_order_by_month = all_prev_orders_clean.groupby(\n",
    "    ['ordno_current','months_before'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Empty Dataset Unique at ordno and months_before level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordno_df = modeling_dataset[['ordno']].copy()\n",
    "ordno_df['key'] = 1\n",
    "\n",
    "months_before_df = pd.DataFrame(np.arange(1,24).reshape(-1,1), columns=['months_before'])\n",
    "months_before_df['key']=1\n",
    "\n",
    "ordno_months_before_df = ordno_df.merge(months_before_df, on='key')\n",
    "del(ordno_months_before_df['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ordno_months_before_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Dataset of Last 24 Months of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_orders_by_month = ordno_months_before_df.merge(\n",
    "    all_prev_order_by_month, \n",
    "    left_on=['ordno', 'months_before'],\n",
    "    right_on=['ordno_current', 'months_before'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_orders_by_month = previous_orders_by_month.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(ordno_months_before_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge previous_orders_by_month with the dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_vars = modeling_dataset.drop(['custno'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dependent_vars.shape[0] == len(set(dependent_vars['ordno']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pd = previous_orders_by_month.merge(dependent_vars, on='ordno',how='left')\n",
    "final_pd = final_pd[final_pd['months_before']<=14].sort_values(by=['ordno', 'months_before']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pd.to_pickle('data/final_pd_previous_orders.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_vars.to_pickle('data/dependent_vars_previous_orders.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assert final_pd[['ordno', 'months_before']].drop_duplicates().shape[0] == final_pd.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pd = final_pd.drop(['ordno_current', 'months_before', 'days_before'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordno_df.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in dir():\n",
    "    if isinstance(eval(var), pd.core.frame.DataFrame):\n",
    "        print(50*'=')\n",
    "        print(var)\n",
    "        print(eval(var+'.memory_usage(deep=True).sum()'))\n",
    "\n",
    "print(alldfs) # df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(p1_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(p2_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Between Train and Test\n",
    "X_Orders.shape = (-1, 14, 254)\n",
    "X_Month.shape = (-1,1)\n",
    "Y.shape = (-1, 6)\n",
    "\n",
    "X_Events.shape = ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dependent_vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(dependent_vars['ordno'])) == len(set(final_pd['ordno']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Orders From Counts to BInary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_vars[\n",
    "    ['P1:1.0', 'P1:2.0', 'P1:3.0', 'P1:4.0', 'P1:5.0', 'P1:7.0']\n",
    "] = (dependent_vars[\n",
    "    ['P1:1.0', 'P1:2.0', 'P1:3.0', 'P1:4.0', 'P1:5.0', 'P1:7.0']\n",
    "]>0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd = final_pd[final_pd['orderdate']> pd.to_datetime('2018-09-1')]\n",
    "test_dependent_pd = dependent_vars[dependent_vars['orderdate']> pd.to_datetime('2018-09-1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(test_pd['orderdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(test_pd['ordno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_orders = test_pd.drop(\n",
    "    ['ordermonth','P1:1.0', 'P1:2.0', 'P1:3.0', 'P1:4.0', 'P1:5.0', 'P1:7.0'],\n",
    "    axis=1\n",
    ").values\n",
    "\n",
    "test_X_orders = test_X_orders.reshape((-1,14, 253))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_X_order_month = test_dependent_pd['ordermonth'].values.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y_order = test_pd[['P1:1.0', 'P1:2.0', 'P1:3.0', 'P1:4.0', 'P1:5.0', 'P1:7.0']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = final_pd[final_pd['orderdate']<= pd.to_datetime('2018-09-1')]\n",
    "train_dependent_pd = dependent_vars[dependent_vars['orderdate']<= pd.to_datetime('2018-09-1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_orders = train_pd.drop(\n",
    "    ['P1:1.0', 'P1:2.0', 'P1:3.0', 'P1:4.0', 'P1:5.0', 'P1:7.0'],\n",
    "    axis=1\n",
    ").values\n",
    "\n",
    "train_X_orders = train_X_orders.reshape((-1,14, 254))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = final_pd[final_pd['orderdate']<= pd.to_datetime('2018-09-1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_pd.drop(\n",
    "    ['P1:1.0', 'P1:2.0', 'P1:3.0', 'P1:4.0', 'P1:5.0', 'P1:7.0'],\n",
    "    axis=1\n",
    ").values\n",
    "\n",
    "train_X = train_X.reshape((-1,14, 254))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(train_pd['orderdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_pd.drop(\n",
    "    ['P1:1.0', 'P1:2.0', 'P1:3.0', 'P1:4.0', 'P1:5.0', 'P1:7.0'],\n",
    "    axis=1\n",
    ").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = final_pd[['P1:1.0', 'P1:2.0', 'P1:3.0', 'P1:4.0', 'P1:5.0', 'P1:7.0']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordno_df = modeling_dataset[['ordno']].copy()\n",
    "ordno_df['key'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prev_orders_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Junk Below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previous Order Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prev_order_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Purchase Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order_count_sum(all_previous_orders, min_b4, max_b4):\n",
    "    relevant_previous_orders = all_previous_orders[\n",
    "        (all_previous_orders['days_before']>min_b4) \n",
    "        & (all_previous_orders['days_before']< max_b4)\n",
    "    ]\n",
    "    del(relevant_previous_orders['days_before'])\n",
    "    \n",
    "    order_count_sum = relevant_previous_orders.groupby('ordno_current', as_index=False).sum()\n",
    "    \n",
    "    # Fix Column Names\n",
    "    agg_cols = list(order_count_sum.columns)[1:]\n",
    "    new_cols = [x+f'_{min_b4}_{max_b4}' for x in agg_cols]\n",
    "    new_cols = ['ordno_current'] + new_cols\n",
    "    order_count_sum.columns = new_cols\n",
    "\n",
    "    return order_count_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_count_sum_0_30 = get_order_count_sum(all_prev_orders_clean,0,30)\n",
    "order_count_sum_30_350 = get_order_count_sum(all_prev_orders_clean,30,350)\n",
    "order_count_sum_350_380 = get_order_count_sum(all_prev_orders_clean,350,380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_count_sum_0_30.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(order_count_sum_0_30['ordno_current'])) == order_count_sum_0_30.shape[0]\n",
    "assert len(set(order_count_sum_30_350['ordno_current'])) == order_count_sum_30_350.shape[0]\n",
    "assert len(set(order_count_sum_350_380['ordno_current'])) == order_count_sum_350_380.shape[0]\n",
    "\n",
    "assert len(set(modeling_dataset['ordno'])) == modeling_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_dataset_orders = modeling_dataset.merge(\n",
    "    order_count_sum_0_30,\n",
    "    left_on='ordno', right_on='ordno_current',\n",
    "    how='left'\n",
    ").merge(\n",
    "    order_count_sum_30_350,\n",
    "    left_on='ordno', right_on='ordno_current',\n",
    "    how='left'\n",
    ").merge(\n",
    "    order_count_sum_350_380,\n",
    "    left_on='ordno', right_on='ordno_current',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all Orders are stored\n",
    "assert modeling_dataset.shape[0]==modeling_dataset_orders.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(modeling_dataset_orders['ordno'])) == modeling_dataset_orders.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modeling_dataset_orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Online Data\n",
    "- Aggregate to Session Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "online = pd.read_csv('data/online.csv')\n",
    "\n",
    "# Convert to Datetime\n",
    "online['dt'] = pd.to_datetime(online['dt'])\n",
    "\n",
    "# Fill in Missing Values with Dummie Value\n",
    "online['event1'] = online['event1'].fillna(-1)\n",
    "\n",
    "# Give clear category name for when it's split out to all the columns\n",
    "online['event1'] = online[['event1']].apply(lambda row: rename_categories('E1',row[0]), axis=1)\n",
    "online['event2'] = online[['event2']].apply(lambda row: rename_categories('E2',row[0]), axis=1)\n",
    "online['category'] = online[['category']].apply(lambda row: rename_categories('Cat',row[0]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Out Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_dummies = pd.get_dummies(online['event1'])\n",
    "e2_dummies = pd.get_dummies(online['event2'])\n",
    "cat_dummies = pd.get_dummies(online['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_vars = list(e1_dummies.columns) + list(e2_dummies.columns) + list(cat_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_expanded = pd.concat([online, e1_dummies, e2_dummies, cat_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary for Aggregation\n",
    "agg_dict = {}\n",
    "for event_var in event_vars:\n",
    "    agg_dict[event_var] = 'sum'\n",
    "agg_dict['dt'] = 'min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_sessions = online_expanded.groupby(['custno', 'session'], as_index=False).agg(agg_dict).copy()\n",
    "\n",
    "online_sessions['start_time'] = online_sessions['dt']\n",
    "del(online_sessions['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_sessions.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_and_dates = modeling_dataset_orders[['ordno','custno','orderdate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_and_sessions = orders_and_dates.merge(online_sessions, on='custno').copy()\n",
    "\n",
    "orders_and_sessions = orders_and_sessions[\n",
    "    orders_and_sessions['orderdate']>orders_and_sessions['start_time']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_and_sessions['days_before'] = (\n",
    "    orders_and_sessions['orderdate'] - orders_and_sessions['start_time']\n",
    ").astype('timedelta64[s]')/3600/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_and_sessions.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_and_sessions.head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_and_sessions_clean = orders_and_sessions[\n",
    "    [\n",
    "        'ordno','days_before',\n",
    "        'E1:-1.0', 'E1:1.0', 'E1:2.0', 'E1:4.0', 'E1:5.0', 'E1:6.0',\n",
    "        'E1:7.0', 'E1:8.0', 'E1:9.0', 'E1:10.0', 'E1:11.0',\n",
    "        \n",
    "        'E2:1', 'E2:2', 'E2:3','E2:4', 'E2:5',\n",
    "        'E2:6', 'E2:7', 'E2:8', 'E2:9', 'E2:10', \n",
    "        \n",
    "        'Cat:1', 'Cat:2', 'Cat:3', \n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_event_sum(all_previous_sessions, min_b4, max_b4):\n",
    "    relevant_previous_sessions = all_previous_sessions[\n",
    "        (all_previous_sessions['days_before']>min_b4) \n",
    "        & (all_previous_sessions['days_before']< max_b4)\n",
    "    ]\n",
    "    del(relevant_previous_sessions['days_before'])\n",
    "    \n",
    "    session_event_sum = relevant_previous_sessions.groupby('ordno', as_index=False).sum()\n",
    "    \n",
    "    # Fix Column Names\n",
    "    agg_cols = list(session_event_sum.columns)[1:]\n",
    "    new_cols = [x+f'_{min_b4}_{max_b4}' for x in agg_cols]\n",
    "    new_cols = ['ordno'] + new_cols\n",
    "    session_event_sum.columns = new_cols\n",
    "\n",
    "    return session_event_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_event_sum_0_30 = get_session_event_sum(orders_and_sessions_clean,0,30)\n",
    "session_event_sum_30_350 = get_session_event_sum(orders_and_sessions_clean,30,350)\n",
    "session_event_sum_350_380 = get_session_event_sum(orders_and_sessions_clean,350,380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_event_sum_0_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(session_event_sum_0_30['ordno'])) == session_event_sum_0_30.shape[0]\n",
    "assert len(set(session_event_sum_30_350['ordno'])) == session_event_sum_30_350.shape[0]\n",
    "assert len(set(session_event_sum_350_380['ordno'])) == session_event_sum_350_380.shape[0]\n",
    "\n",
    "assert len(set(modeling_dataset['ordno'])) == modeling_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_dataset_full = modeling_dataset_orders.merge(\n",
    "    session_event_sum_0_30,\n",
    "    on='ordno',\n",
    "    how='left'\n",
    ").merge(\n",
    "    session_event_sum_30_350,\n",
    "    on='ordno',\n",
    "    how='left'\n",
    ").merge(\n",
    "    session_event_sum_350_380,\n",
    "    on='ordno',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_dataset_full.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert modeling_dataset_full.shape[0] == modeling_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert modeling_dataset_full.shape[0] == order_totals.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(modeling_dataset_full['ordno'])) == modeling_dataset_full.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up Final Modeling Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Redundant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_vars = [\n",
    "    'ordno_current_x', 'ordno_current_y', 'ordno_current'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_dataset_final = modeling_dataset_full.drop(drop_vars, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling Missing Counts with 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_dataset_final = modeling_dataset_final.fillna(0).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(modeling_dataset_final['orderdate']>pd.to_datetime('2018-12-01'))/modeling_dataset_final.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custno_join[\n",
    "    (custno_join['orderdate']>custno_join['dt'])\n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online = pd.read_csv('data/online.csv')\n",
    "online['dt'] = pd.to_datetime(online['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = pd.read_csv('data/order.csv')\n",
    "order['orderdate'] = pd.to_datetime(order['orderdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custno_join = pd.merge(order,online,how='left',on=['custno'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
